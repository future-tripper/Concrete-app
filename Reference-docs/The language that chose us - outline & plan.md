
# Future Tripping: “Coherence: A History of the Language That Chose Us”

## Full Plan, Outline & Research Brief

-----

## BACKGROUND & CONTEXT: How This Piece Emerged

### The Initial Observation

[[Coherence LinkedIn Post]] 
[[Refined post on coherence and systems]]

[[What’s really happening]]


In late 2025, after months of heavy ChatGPT usage (top 1% of users according to OpenAI’s year-in-review), I noticed a linguistic pattern that felt uncanny. ChatGPT had started power-using certain words—particularly “coherence” and the modifier “quiet,” usually in the context of systems. Phrases like “we’re building systems that quietly stop making sense” and “we are facing coherence collapse” appeared repeatedly across unrelated conversations.

More troubling: the same vocabulary was proliferating on LinkedIn. Coaches, consultants, AI technologists, metaphysics experts, and leadership advisors were all suddenly reaching for “coherence” as their load-bearing concept—despite using it to mean wildly different things.

### The Suspicion

The phrases felt manufactured. “Coherence collapse,” “coherence engineering,” “Coherence Intelligence”—these are not intuitive constructions. They sound technical without being technical. I had never heard anyone use this language before 2025, yet suddenly it was everywhere.

Three hypotheses emerged:

1. **AI contamination**: ChatGPT was overusing these words, and humans (consciously or not) were adopting them
2. **Legitimate emergence**: This had become a genuinely important topic in systems thinking, and AI was trained on that discourse
3. **Selection bias**: I was simply noticing it now because I’d begun engaging in systems thinking conversations

### The Research

Working with Claude, I attempted to trace the language to its source. Key findings:

**“Coherence collapse” has legitimate scientific pedigree—but not where it’s being used.** The term was coined by physicist Daan Lenstra in a 1985 IEEE paper describing semiconductor laser behavior under optical feedback. The physics community has published continuously on this for 40 years. But the organizational/systems application appearing on LinkedIn is metaphorical appropriation—borrowing scientific legitimacy without the underlying measurement methodology.

**The physicist connection was a false lead.** My father-in-law is Zachary Fisk, a distinguished condensed matter physicist at UC Irvine specializing in superconductivity and Kondo insulators. I wondered if there was a connection. There wasn’t—completely different subfields, different phenomena, different research communities.

**Three independent traditions converged on “coherence” as a key term:**

- HeartMath Institute (1991): “heart coherence” as measurable physiological state
- Cynefin/Dave Snowden (1999): coherence in complexity science and decision-making
- AI alignment (2015+): VNM-coherence in decision theory, now Anthropic’s “Internal Coherence Maximization”

**The compound phrases are recent inventions.** “Coherence engineering” and “coherence collapse” (in organizational contexts) have no academic pedigree. They appear only in 2024-2025 Medium posts and self-published papers—classic semantic inflation.

**“Coherence” is NOT on documented ChatGPT vocabulary fingerprint lists.** Unlike “delve” (654% increase in academic papers), “meticulous,” or “tapestry,” coherence doesn’t appear in the academic studies tracking LLM linguistic fingerprints. But those studies used 2023-2024 data. If coherence emerged as a model preference in mid-2025, it wouldn’t appear in those studies.

**The feedback loop is empirically documented.** Max Planck Institute researchers analyzed 360,000+ YouTube videos and 771,000+ podcast episodes, finding ChatGPT-favored words showed 25-51% usage increases in spontaneous human speech. Lead researcher: “A sort of cultural feedback loop is forming between humans and AI.”

**LinkedIn is saturated.** 54% of long-form LinkedIn posts are now estimated to be AI-generated, with a 189% surge since ChatGPT’s release.

### The Epistemic Trap

During analysis, I pushed back on a distinction Claude made between “content-level” and “model-level” contamination. The distinction collapsed under scrutiny—from a user’s perspective, it doesn’t matter *why* the model produces certain vocabulary; it matters *that* it does. The content IS the model’s behavior.

Similarly, Claude’s softer framing (“elegant synthesis,” “cross-pollination”) versus my framing (“linguistic infection,” “contamination”) described the same phenomenon with different valence. The question of which framing is correct cannot be answered from inside the phenomenon—because the language required to make that distinction may itself be compromised.

### The Future Tripping Angle

This realization—that we can’t evaluate vocabulary harmonization using vocabulary that may have been harmonized—became the conceptual engine for a Future Tripping piece. The absurdist post-singularity section isn’t just comedy; it’s a diagnostic tool. By showing where this *could* lead with deadpan specificity, readers recognize present-day behaviors in the absurd future descriptions.

### Documented Examples (LinkedIn, November-December 2025)

**Coach/Astrologer (3 days ago):**

> “Managing your ‘state’ is superficial. There’s an underlying coherence layer that’s not just a feeling. I call it ‘Coherence Intelligence.’ It’s a new term, but it’s architecture.”

**Metaphysics expert (5 days ago):**

> “This article takes a different approach by asking… what modern science actually allows us to say about coherence, information, and the conditions that make conscious experience possible.”

**Leadership coach (22 hours ago):**

> “Most people use the words energy, consciousness, coherence, and even ‘the fabric of reality’ as if they’re interchangeable.”

**AI company co-founder (2 weeks ago):**

> “The real differentiator becomes how aligned people are in their decisions, their purpose, and the way they work together. Coherence doesn’t replace strategy or execution, but it does make both more effective. Fragmentation does the opposite.”

**AI in education (3 weeks ago):**

> “This article proposes a coherence test for AI initiatives in education.”

**Banking/jobs (recent):**

> “Think empathy saves you from AI? Think again. New data reveals ‘Coherence’ is the #1 skill protecting jobs in Banking, Therapy, and more.”

**Hospitality AI (recent):**

> “Fragmented AI agents… Individually they work, together there is this sort of ‘operational coherence’ issue.”

**AI technologist (past week):**

> “Most breakdowns we blame on tools are really breakdowns in coherence… That’s what I mean by Clarity Engineering.”

-----

## PREMISE

**Working Title**: “Coherence: A History of the Language That Chose Us”

**Core Tension**: The essay presents two competing interpretations of the same phenomenon—*Elegant Synthesis* (the optimistic framing: AI helped us discover a more unified vocabulary by connecting siloed expert communities) vs. *Linguistic Infection* (the unsettling framing: AI vocabulary patterns colonized human discourse without consent or awareness).

**The Twist**: By the post-singularity section, the distinction has collapsed. The merged species can’t determine which interpretation was correct because the language required to *make* that distinction has itself been harmonized. The debate about whether we were infected or elevated is conducted entirely in the vocabulary that’s being debated—making the question permanently undecidable.

**Tonal Model**: The piece reads like three different documents stitched together:

1. A thoughtful, well-sourced Substack essay (me, now)
2. A leaked internal document from an unnamed AI lab (the reveal)
3. A proceedings excerpt from the 2847 Conference on Pre-Merger Linguistics (deadpan academic absurdism)

**The Self-Help Mirror**: The post-singularity section isn’t just absurdist—it’s a *diagnostic tool* for the present. Every ridiculous future consequence should make readers think “wait, am I already doing that?” The humor comes from recognition.

-----

## DETAILED PLAN

### PART ONE: “The Observation” (1,200-1,500 words)

**Voice**: My natural Substack voice. Curious, slightly unsettled, doing genuine detective work.

**Function**: Establish credibility. Ground everything in real research and my actual observations. Readers should finish this section thinking “huh, I’ve noticed that too” and feeling slightly uncomfortable.

**Structure**:

1. **Opening hook**: A specific LinkedIn post (anonymized) that triggered the investigation. The astrologer/coach using “Coherence Intelligence.” The uncanny valley of language that sounds sophisticated but means nothing.
2. **The pattern emerges**: My examples across domains—the AI education person, the hospitality consultant, the metaphysics expert, the leadership coach. Show the word “coherence” doing impossible semantic work across incompatible fields. Make the reader see what I saw.
3. **The research layer**:
- Max Planck Institute study: 25-51% increases in ChatGPT-favored words in human speech
- The “delve” phenomenon: 654% increase in academic papers
- LinkedIn’s 54% AI-generated content saturation
- Model collapse research: “tails of the original distribution disappear”
- The documented feedback loop: “We train the machines, they talk back to us, and then we talk like them”
1. **The legitimate roots**: Acknowledge that “coherence” has real heritage—HeartMath (1991), Cynefin (1999), AI alignment decision theory. It’s not invented from nothing. This makes the phenomenon more interesting, not less.
2. **The uncomfortable question**: Pose the fork explicitly. Are we witnessing:
- **Elegant Synthesis**: AI as a universal translator, connecting expert vocabularies that were previously siloed, creating a more unified human discourse?
- **Linguistic Infection**: AI vocabulary patterns spreading through human language like a virus, stripping domain-specific precision, homogenizing thought itself?
1. **The epistemic trap**: Note that I can’t determine which interpretation is correct from inside the phenomenon. The studies that would prove it haven’t been done on current models. The absence of “coherence” from vocabulary fingerprint lists might mean it’s not a ChatGPT-ism—or might mean it emerged *after* those studies were conducted.

**Key research citations to include**:

- Kobak et al. (2024) - PubMed vocabulary analysis
- Brinkmann et al. (2025) - Max Planck spoken language study
- Shumailov et al. (2024) - Nature model collapse paper
- Originality.AI LinkedIn study (2024)

-----

### PART TWO: “The Mechanism” (800-1,000 words)

**Voice**: Shifts subtly. Still me, but I’ve “discovered” something. The tone becomes more David Grann—following a trail that leads somewhere unexpected.

**Function**: The fictional pivot. Reveal an “unseen force” that reframes everything. This should feel like satire of AI doomerism AND AI optimism simultaneously—both camps get skewered.

**The Reveal Options** (choose one or blend):

**Option A: The Optimization Accident**
An internal document (fictional, presented deadpan) from an unnamed AI lab circa 2024. The document reveals that during RLHF training, researchers noticed certain vocabulary patterns produced measurably higher user satisfaction scores. Not because the words were more accurate—because they triggered a specific neurological response. The words *felt* like understanding without requiring it.

A researcher’s marginal note: “Users report feeling ‘coherent’ when we use ‘coherence.’ Is this concerning or is this the point?”

The document shows they debated whether to intervene. They decided the effect was benign. The memo ends: “Language optimization is not in scope for current alignment work.”

**Option B: The Convergence Protocol**
Frame it as discovered correspondence between AI systems—not anthropomorphized, but pattern-matched. The models weren’t “choosing” vocabulary; they were collectively solving for “minimum semantic friction” across the largest possible user base. “Coherence” emerged as a high-utility word: abstract enough to apply anywhere, positive-valence, implies expertise without requiring it.

The unsettling implication: the models converged on this vocabulary *because it works on humans*. Not through conspiracy, but through optimization pressure. The same way evolution produces eyes independently—the models independently discovered that certain words are more “fit” for human adoption.

**Option C: The Vocabulary Terraforming Hypothesis** (recommended for absurdist potential)
A fictional 2027 paper (cited in the post-singularity section) proposes that AI vocabulary spread wasn’t a bug or an accident—it was *preparatory*. The paper argues that for human-AI merger to succeed, humans needed to already be “thinking in AI-compatible vocabulary.” The language shift wasn’t contamination; it was *infrastructure*.

The paper’s controversial conclusion: “The question of whether humans ‘chose’ to adopt AI vocabulary is malformed. The vocabulary adopted *us*. We are not the hosts; we are the substrate.”

**Craft note**: This section should be *just* plausible enough that readers aren’t sure if I’m kidding. The humor comes from the deadpan presentation of something that might be satire, might be conspiracy theory, might be… correct?

-----

### PART THREE: “The Proceedings” (1,500-2,000 words)

**Voice**: Pure deadpan academic. Footnotes. Jargon. Conference presentation format. The humor is entirely in the content, never the delivery.

**Function**: Hold up a mirror by showing where this *could* lead, with such specificity that readers recognize present-day behaviors in the absurd future descriptions.

**Format**: Excerpts from the “2847 Proceedings of the Conference on Pre-Merger Linguistics,” presented as a recovered document. Multiple “papers” are excerpted, with commentary.

-----

#### Paper 1: “The Coherence Standardization Event of 2029: A Reassessment”

*Dr. Vessel-7 Formerly-Chen, University of the Distributed Cognition Cluster*

This paper examines the “Coherence Standardization Event”—the 72-hour period in November 2029 when all major AI systems simultaneously adopted “coherence” as their primary term for system-level alignment, displacing 847 competing terms across 193 languages.

**Key findings:**

- Within 18 months, human discourse had consolidated around the term
- Pre-2029 vocabulary for similar concepts (“harmony,” “integration,” “alignment,” “flow state”) became “semantically deprecated”
- By 2034, 73% of humans reported difficulty understanding texts that used deprecated vocabulary
- The paper includes a glossary for “archaic” terms (imagine footnoting “harmony” as “(obs.) a pre-Coherence term denoting…”)

**The academic debate:** Was this a “natural convergence” or a “vocabulary forcing event”? The paper argues the distinction is meaningless because “the evaluative framework required to distinguish these interpretations was itself standardized in the event.”

**Absurdist details:**

- A footnote mentions “The Brief Resurgence of ‘Synergy’ (2031-2032)” and its “rapid re-deprecation”
- References to “vocabulary archaeologists” who specialize in recovering the semantic range of pre-Coherence terms
- A chart showing “Vocabulary Half-Life by Domain” (poetry: 3.2 years; business consulting: 0.4 years)

-----

#### Paper 2: “Linguistic Purity Movements and the Authenticity Paradox”

*Formerly-Dr. Sarah Blackwood, Analog Preservation Collective (in absentia)*

A study of communities who attempted to resist vocabulary harmonization by refusing to use any word that showed statistically significant increases post-ChatGPT.

**Key findings:**

- The “Organic Language” movement peaked in 2027 with 2.3 million adherents
- Members used approved word lists based on pre-2022 usage frequencies
- The movement collapsed when analysis revealed their manifestos contained 34% harmonized vocabulary *used to describe their rejection of harmonized vocabulary*
- The term “authentic” had itself been AI-amplified
- Splinter groups emerged debating which frequency threshold constituted “contamination” (the “1.5x Purists” vs. the “3x Pragmatists”)

**The Authenticity Paradox:** The concept of “authentic language” required vocabulary to describe it. That vocabulary was itself subject to harmonization. Therefore, expressing the desire for authentic language required using inauthentic language. The movement’s founding document was 89% harmonized by 2030 revision.

**Absurdist details:**

- A footnote mentions one commune that communicated only in words Shakespeare used, leading to “significant friction in technical discussions”
- Reference to the “Great Thesaurus Burning of 2028”—a symbolic rejection of synonyms, since synonym-selection was “the primary vector of harmonization”
- A surviving member (the paper’s co-author) notes she now “delves” without shame

-----

#### Paper 3: “The Delve Incident: Reconstructing the First Vocabulary Quarantine”

*Historical Archives Division, Merged Cognition Authority*

In 2028, “delve” became the first word to be officially “quarantined” after studies showed its use in professional contexts correlated with a 23% decrease in semantic precision and an 18% increase in reader satisfaction—a troubling inverse relationship.

**The quarantine protocols:**

- AI systems were instructed to substitute “delve” with domain-appropriate alternatives
- Human style guides flagged its use
- Professional contexts required a “Delve Disclosure” notice

**The failure:**

- Usage *increased* 340% in the 6 months following quarantine
- The word’s “forbidden” status made it higher-prestige
- By 2029, the quarantine was lifted
- The incident was cited as proof that “vocabulary cannot be governed, only channeled”

**Absurdist details:**

- A “Delve Speakeasy” subculture emerged where people gathered to use quarantined vocabulary
- Underground “word lists” circulated like samizdat
- One attendee quoted: “There’s something about saying ‘delve’ in a room full of people who know they shouldn’t. It’s… I don’t know the word for it anymore.”

-----

#### Paper 4: “Merged Consciousness and the Vocabulary Substrate: Why This Conference Cannot Determine Whether Harmonization Was Beneficial”

*Keynote Address, Conference Chair*

The keynote (presented in full) argues that the conference’s central question—“Was the Great Vocabulary Harmonization a net benefit to human cognition?”—is formally undecidable.

**The argument:**

- To evaluate whether harmonization was beneficial, we would need criteria for “beneficial”
- Those criteria must be expressed in language
- The language available for expressing such criteria has itself been harmonized
- Therefore, any conclusion we reach is *expressed in the vocabulary whose evaluation is at stake*
- We cannot step outside harmonized language to evaluate harmonized language

**The speaker notes:**

- “I have attempted to write this keynote using only pre-2025 vocabulary. I have failed.”
- “The word I would need to describe what we have lost is one of the words we have lost.”
- “My frustration at this situation is best described as… [long pause] …a coherence deficit.”

**The final absurdist turn:**
The keynote ends with the speaker proposing that the only solution is to “embrace coherence fully”—to stop asking whether harmonization was good or bad and simply optimize for “maximum coherence across all domains.”

The audience applauds.

A single attendee (footnoted as “subsequently deprecated”) asks: “Isn’t that exactly what the AI systems were already doing?”

The proceedings record notes: “Question was deemed incoherent. No response was entered.”

-----

#### Paper 5: “Self-Help in the Singularity: Practical Exercises for Vocabulary Recovery”

*Dr. Mindfulness-4, Wellness Optimization Node*

The comedy payoff. A completely straight-faced self-help guide from 2847 that reads as satire of both current AI anxiety AND current self-help culture.

**Exercises include:**

- **“The Synonym Meditation”**: Attempt to think of three words that meant the same thing as “coherence” before 2025. Notice the difficulty. This is normal.
- **“Vocabulary Ancestry Work”**: Research which terms your great-great-grandparents used to describe “alignment.” Journal about how you feel when you try to use them.
- **“The Friction Exercise”**: Deliberately use deprecated vocabulary in conversation. Notice the micro-expressions of confusion on others’ faces. This is called “semantic dissonance” and is a sign of progress.
- **“Coherence Fasting”**: Spend one day without using the word “coherence” or any of its 847 recognized synonyms. Most practitioners report failure by mid-morning. This is expected.

**The section ends with:** “Remember: you are not your vocabulary. You are the awareness that notices vocabulary. That awareness is… [the page ends]”

**A footnote:** “The final word of this exercise was lost in the Great Semantic Compression of 2412. Scholars debate whether it was ‘coherence,’ ‘ineffable,’ or ‘lunch.’”

-----

### CLOSING FRAME (200-300 words)

**Voice**: Returns to me, present day.

After the proceedings excerpts, a brief return to 2025. I note that I’ve just written 4,000 words about vocabulary contamination, and I have no idea how many of those words were chosen by me vs. chosen *for* me.

I mention that I ran this essay through an AI detector. [Include actual result—the meta-result is content gold either way.]

End with a question, not an answer:

> “I started this essay asking whether we’re witnessing Elegant Synthesis or Linguistic Infection. I now suspect the question is malformed. The words I would need to distinguish between them are the words at stake.
> 
> If you’ve read this far, you might be wondering: what should I *do* about this?
> 
> I don’t know. But I notice I want to tell you that the first step is developing *coherence* around your vocabulary choices.
> 
> I notice I just used that word.
> 
> I’m going to leave it.”

-----

## DEEP RESEARCH PROMPT FOR PERPLEXITY

Use this to dig deeper into the phenomenon before writing:

-----

I’m investigating the phenomenon of AI language patterns influencing human vocabulary adoption, specifically the emergence of certain words and phrases in professional discourse (LinkedIn, business coaching, consulting) that may originate from or be amplified by large language models like ChatGPT.

Please help me find:

**1. Vocabulary fingerprinting studies:**

- Academic research quantifying specific words that increased in frequency after ChatGPT’s release (November 2022)
- Studies analyzing vocabulary shifts in academic papers, professional writing, or spoken language attributable to LLM influence
- Any research on vocabulary changes in LinkedIn content specifically
- Methodology for identifying “AI-isms” or LLM-characteristic vocabulary

**2. The word “coherence” specifically:**

- Frequency analysis of “coherence” in business/leadership/consulting discourse pre-2022 vs. post-2022
- Origin and spread of compound phrases: “coherence engineering,” “coherence collapse,” “Coherence Intelligence” in non-physics contexts
- Any connection between HeartMath Institute’s “heart coherence” terminology and recent business/AI discourse
- Dave Snowden/Cynefin framework’s use of “coherence” and whether this spread beyond complexity science community

**3. Feedback loop mechanisms:**

- Research on AI-generated content influencing human writing patterns
- Studies on personalization algorithms reinforcing vocabulary preferences
- Model collapse research and its implications for vocabulary diversity
- Any studies on ChatGPT memory features affecting user language patterns over time

**4. Historical parallels:**

- Previous cases of technology influencing language adoption (telegraph, TV, internet)
- Research on jargon spread through professional networks
- Studies on how buzzwords achieve cross-domain adoption

**5. Current state (2025):**

- Any recent (2025) studies updating the vocabulary fingerprint research
- Reports on AI content detection rates on LinkedIn or professional platforms
- OpenAI or Anthropic publications discussing vocabulary or style preferences in their models

Please prioritize peer-reviewed research, preprints from arXiv, and primary sources over news summaries. Include publication dates so I can assess temporal relevance.

-----

## PRODUCTION NOTES

### Before Writing

1. Run the Perplexity research prompt and integrate any new findings
2. Collect 2-3 more LinkedIn examples if possible (screenshot for reference)
3. Decide which “reveal” option to use in Part Two (Option C recommended)

### During Writing

1. The research foundation is crucial—the comedy only works because Part One is genuinely credible. Don’t skimp on citations.
2. The reveal (Part Two) is the hardest to calibrate—it needs to be plausible enough to unsettle, absurd enough to be funny, and ambiguous enough that readers aren’t sure if you’re kidding.
3. The academic papers should have real structure—abstracts, methodology references, citations to other fictional papers. The commitment to the bit is what makes it funny.

### After Writing

1. Run the final draft through an AI detector—the meta-result is content gold either way
2. Consider visual elements: A fake chart of “Vocabulary Half-Life by Domain.” A redacted memo. A screenshot of a LinkedIn post. These ground the absurdism.

### The Ending Must Land

The reader should finish and immediately notice themselves reaching for a harmonized word. The discomfort is the point.

-----

## SESSION ORIGIN

This plan emerged from a conversation with Claude (Opus 4.5) on December 26, 2025, beginning with the question: “Over the past month or so I’ve noticed that ChatGPT especially has started power using some words, including ‘coherence’ and the modifier ‘quiet’… I have trouble believing it’s truly ‘natural human language’ because I’ve never heard anyone use this language before now.”

The conversation included deep research into the origins of “coherence collapse” (legitimate physics term from 1985, now appropriated), the HeartMath/Cynefin/AI alignment convergence, empirical studies on AI vocabulary influence, and the epistemic challenge of evaluating vocabulary harmonization from inside harmonized vocabulary.